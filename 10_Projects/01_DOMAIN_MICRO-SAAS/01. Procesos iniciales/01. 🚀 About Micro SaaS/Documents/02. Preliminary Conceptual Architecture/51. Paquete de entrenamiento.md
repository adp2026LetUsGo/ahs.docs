
¡Perfecto, Armando! Ya dejé listo un **paquete de entrenamiento** en Python para que generes tu `model.onnx` y lo coloques en `src/Ml.Inference/models/`.

**Descarga directa:** [ml-training-predictive-risk.zip](blob:https://www.microsoft365.com/59e59986-1620-46e6-b314-55a72c56bd30)

Dentro encontrarás:

- `train.py` — script de entrenamiento y **exportación a ONNX**
- `requirements.txt` — dependencias (scikit‑learn, onnx, skl2onnx, etc.)
- `data/input.csv` — CSV de ejemplo con el **esquema mínimo** (puedes reemplazarlo por tus datos)
- `artifacts/` — carpeta para métricas y metadatos
- `README.md` — instrucciones rápidas

---

## Cómo usarlo (paso a paso)

1. **Descomprime** el ZIP dentro de: ahs/log-suite/products/predictive-risk-mvp/ml-training/
    
2. **(Recomendado) Crea y activa un entorno virtual**
    
    python -m venv .venv
    
    # Windows:
    
    .venv\Scripts\activate
    
    # macOS/Linux:
    
    source .venv/bin/activate
    
3. **Instala dependencias** pip install -r requirements.txt
    
4. **Coloca tus datos** en `./data/input.csv` con estas columnas mínimas (puedes añadir más):
    
    - `shipment_id` (string)
        
    - `route` (string)
        
    - `carrier` (string)
        
    - `packaging_type` (string)
        
    - `product` (string)
        
    - `shipment_size` (float)
        
    - `accumulated_delay_hours` (float)
        
    - `avg_external_temp_c` (float)
        
    - `progress_percent` (float 0..100)
        
    - **`temperature_excursion` (int {0,1})** ← _la variable objetivo_
        
    
    > El pipeline detecta automáticamente columnas numéricas vs. categóricas (One‑Hot para categóricas y StandardScaler para numéricas).
    
5. **Entrena y exporta el modelo ONNX**
    
    python train.py \
    
      --input ./data/input.csv \
    
      --target temperature_excursion_ _\_
    
      _--version 0.1.0 \_
    
      _--output-onnx ../src/Ml.Inference/models/model.onnx \_
    
      _--output-meta ./artifacts/model_meta.json
    
    - Esto genera:
        - `../src/Ml.Inference/models/model.onnx` → **tu modelo listo para la API**
        - `./artifacts/metrics.json` → **Precision, Recall, PR AUC, n_val**
        - `./artifacts/model_meta.json` → versión, columnas, métricas
6. **Verifica métricas**
    
    type artifacts\metrics.json   # Windows
    
    cat artifacts/metrics.json    # macOS/Linux
    

---

## Cómo lo consume la API

El proyecto **Presentation.Api** carga el modelo desde:

var modelPath = Path.Combine(AppContext.BaseDirectory, "models", "model.onnx");

Por eso, tras entrenar, el archivo debe existir en:

```
ahs/log-suite/products/predictive-risk-mvp/src/Ml.Inference/models/model.onnx
```

(El `.keep` solo mantiene la carpeta en control de versiones; **puedes dejarlo o borrarlo**).

---

## ¿Qué hace exactamente el script?

- Split **train/valid** (estratificado)
- **Preprocesamiento**:
    - `StandardScaler` para numéricas
    - `OneHotEncoder` para categóricas
- Modelo: `LogisticRegression` + **`CalibratedClassifierCV`** (isotónica) para calibrar probabilidades
- Métricas: **Precision**, **Recall**, **PR AUC**
- Exporta a **ONNX** usando `skl2onnx`
- Guarda **metadatos** (versión, columnas) para trazabilidad

---

> ## Siguientes mejoras opcionales
> 
> - Añadir **pipeline de validación cruzada** y _early stopping_ (si cambias a modelos tipo GBM)
> - Exportar **umbral óptimo** (p. ej. maximizar F‑beta o costo esperado)
> - Generar **explicabilidad SHAP** fuera de línea y guardarla por lote
> - Script para **validación de drift** (PSI) y _retraining_ periódico
> 
> ¿Quieres que te agregue ahora un **notebook** (`.ipynb`) con visualizaciones (Curva PR, matriz de confusión) y un **script de SHAP** para análisis de factores?