##### AdÃ¡ptalo para predicciÃ³n en trÃ¡nsito, agrega scoring por lote en C# e Incluye endpoint para SHAP

Perfectâ€”hereâ€™s your **inâ€‘transit** adaptation, plus **batch scoring in C#** and a practical **SHAP endpoint** design that fits the hybrid setup (Python training + C# serving via ONNX). Iâ€™m keeping everything in **English** as requested.

---

## âœ… What changes for _inâ€‘transit_ prediction

**Goal:** Predict _before arrival_ while the shipment is already moving, using **partial telemetry** and evolving context.

**Use features that are known â€œso farâ€:**

- `Delay_Sofar_Hrs` â€” cumulative delay up to now
- `External_Temp_Rolling_Avg` â€” rolling avg of external temperature up to now
- `Pct_Elapsed_Transit` â€” % of planned transit completed
- `Deviation_Flag` â€” route deviation seen so far (0/1)
- `Route_ID`, `Carrier`, `Packaging_Type`, `Product_Type`, `Shipment_Size`
- `Holiday_Period_Flag`, cyclic time features from `Departure_Time` (month/hour â†’ sin/cos)
- **Target** (for training): `Temp_Excursion` (1/0), observed at delivery in historical data

> **Leakage guardrail:** Do **not** use final/realized values (e.g., full actual `Transit_Time_Hrs` or fullâ€‘journey `External_Temp_Avg`). Use â€œsoâ€‘farâ€/rolling/expected equivalents only.

---

## ðŸ§  Training in Python (scikitâ€‘learn) and costâ€‘based threshold

Below is a **notebookâ€‘equivalent `.py` script** tailored for **inâ€‘transit**. It:

1. Reads `shipments.csv`
2. Builds inâ€‘transit features
3. Trains a **calibrated RandomForest**
4. Selects the **optimal threshold** by minimizing expected cost (FN vs FP)
5. Saves artifacts (`.pkl`, optional `.onnx`, `threshold.txt`, `features_used.csv`)
6. Writes `predictions.csv` (test split) with the chosen threshold
7. (Optional) computes **SHAP** values for test predictions and saves `shap_values.csv`

> Feel free to switch to **XGBoost/LightGBM**; TreeSHAP tends to be even stronger with gradient boosting models.

# train_temperature_risk_in_transit.py

# -_- coding: utf-8 -_-

"""

In-transit training script:

- Loads shipments.csv

- Uses so-far telemetry features (delay, rolling temp, pct progress, deviation)

- Temporal split

- Calibrated RandomForest (probability quality)

- Cost-based threshold selection

- Saves artifacts (.pkl, optional .onnx), predictions.csv

- (Optional) SHAP values per test sample

"""

  

import os, numpy as np, pandas as pd

from pathlib import Path

from sklearn.compose import ColumnTransformer

from sklearn.preprocessing import OneHotEncoder, StandardScaler

from sklearn.pipeline import Pipeline

from sklearn.ensemble import RandomForestClassifier

from sklearn.calibration import CalibratedClassifierCV

from sklearn.metrics import roc_auc_score, average_precision_score

import joblib

  

# Optional ONNX export

try:

Â Â Â  from skl2onnx import convert_sklearn_

Â Â Â  _from skl2onnx.common.data_types import FloatTensorType, StringTensorType

Â Â Â  ONNX_AVAILABLE_ _= True_

_except Exception:_

Â Â Â  _ONNX_AVAILABLE = False

  

# Optional SHAP

try:

Â Â Â  import shap

Â Â Â  SHAP_AVAILABLE_ _= True_

_except Exception:_

Â Â Â  _SHAP_AVAILABLE = False

  

# Config

DATA_PATH_ _= Path("shipments.csv")_

_OUT_DIR = Path("model_artifacts"__)_

_OUT_DIR.mkdir(exist_ok__=True)_

_TARGET = "Temp_Excursion"

  

# Cost weights: set with operations team

COST_FALSE_NEGATIVE = 10.0Â Â  # missing a risky shipment

COST_FALSE_POSITIVE = 1.0Â Â Â  # mitigating unnecessarily

  

# Load

df = pd.read_csv__(DATA_PATH, parse_dates__=["Departure_Time"])

assert TARGET in df.columns, f"Missing target: {TARGET}"

y = df[TARGET].astype(int)

  

# In-transit candidate features (present-tense, no leakage!)

candidates = [

Â Â Â  "Route_ID"__, "Carrier", "Packaging_Type", "Product_Type"__,_

Â Â Â  _"Shipment_Size",

Â Â Â  "Delay_Sofar_Hrs",

Â Â Â  "External_Temp_Rolling_Avg"__,_

Â Â Â  _"Pct_Elapsed_Transit",_

Â Â Â  _"Deviation_Flag",Â Â Â Â Â Â Â Â Â Â Â Â  # if available (0/1)

Â Â Â  "Holiday_Period_Flag",Â Â Â Â Â Â Â  # if available

Â Â Â  # Time features from Departure_Time_

Â Â Â  _"Month_sin", "Month_cos"__, "Hour_sin", "Hour_cos"_

_]_

_  

# Derive cyclic time features

_

_df["Month"] = df["Departure_Time"].dt.month

df["Hour"]Â  = df["Departure_Time"__].dt.hour_

_df["Month_sin"] = np.sin(2_np.pi_df["Month"]/12)

df["Month_cos"__] = np.cos(2_np.pi_df["Month"]/12)_

_df["Hour_sin"]Â  = np.sin(2_np.pi_df["Hour"]/24)

df["Hour_cos"__]Â  = np.cos(2_np.pi_df["Hour"]/24)_

_  

# Default flags if missing

_

_for flag_col, default_val_ _in [("Holiday_Period_Flag", 0), ("Deviation_Flag", 0)]:

Â Â Â  if flag_col_ _not in df.columns:_

Â Â Â Â Â Â Â  _df[flag_col] = default_val_

_  

# Keep only available columns

features = [c for c in candidates if c in df.columns]

X = df[features].copy()

  

# Temporal split (train past, test future)

_

_df_sorted = df.sort_values__("Departure_Time").reset_index__(drop=True)_

_idx = df_sorted.index

X_sorted_ _= X.loc[idx]_

_y_sorted = y.loc[idx]

  

cut = int(len(df_sorted__) _0.8)__

__X_train, X_test_ _= X_sorted.iloc[:cut], X_sorted__.iloc[cut:]__

__y_train, y_test_ _= y_sorted.iloc[:cut], y_sorted__.iloc[cut:]__

__  

# Preprocess

_

_num_cols = X_train__.select_dtypes(include=[np.number]).columns.tolist()

cat_cols_ _= [c for c in X_train.columns if c not in num_cols__]_

_  

pre = ColumnTransformer(

Â Â Â  transformers=[

_

Â Â Â Â Â Â Â  _("num", StandardScaler(with_mean=False), num_cols__),_

Â Â Â Â Â Â Â  _("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols__),_

Â Â Â  _],_

Â Â Â  _remainder="drop"_

_)_

_  

# Model + calibration

base = RandomForestClassifier(

_

Â Â Â  _n_estimators=400, n_jobs__=-1, class_weight="balanced", random_state__=42_

_)_

_model = CalibratedClassifierCV(base, method="isotonic", cv=3)_

_  

pipe = Pipeline(steps=[("prep", pre), ("model", model)])

_

_pipe.fit(X_train, y_train__)_

_  

# Evaluate & choose threshold by cost

_

_probs = pipe.predict_proba(X_test__)[:, 1]_

_roc = roc_auc_score(y_test, probs)

pr_auc_ _= average_precision_score(y_test, probs)

  

def expected_cost__(prob, y_true, thr, c_fn__, c_fp):

Â Â Â  y_pred_ _= (prob >= thr).astype(int)_

Â Â Â  _FN = np.sum((y_true == 1) & (y_pred_ _== 0))_

Â Â Â  _FP = np.sum((y_true == 0) & (y_pred_ _== 1))_

_

Â Â Â  __return (c_fn_ FN + c_fp_ _* FP) / len(y_true)

  

thr_grid_ _= np.linspace(0.05, 0.95, 91)_

_costs = [expected_cost(probs, y_test__.values, t, COST_FALSE_NEGATIVE, COST_FALSE_POSITIVE) for t in thr_grid]

best_thr_ _= float(thr_grid[int(np.argmin(costs))])

  

print(f"ROC AUC: {roc:.3f} | PR AUC: {pr_auc:.3f} | Best threshold: {best_thr:.2f}")

  

# Save artifacts

joblib.dump(pipe, OUT_DIR_ _/ "temperature_risk_in_transit.pkl")

pd.DataFrame({"feature": features}).to_csv__(OUT_DIR / "features_used.csv"__, index=False)_

_with open(OUT_DIR / "threshold.txt", "w") as f:

Â Â Â  f.write(str(best_thr__))_

_  

# Optional ONNX export (preprocessing + estimator)

_

_if ONNX_AVAILABLE:

Â Â Â  # Provide ONNX input types matching your features

Â Â Â  initial_types_ _= []_

Â Â Â  _for c in cat_cols:

Â Â Â Â Â Â Â  initial_types__.append((c, StringTensorType([None, 1])))_

Â Â Â  _for c in num_cols:

Â Â Â Â Â Â Â  initial_types__.append((c, FloatTensorType([None, 1])))_

Â Â Â  _try:_

Â Â Â Â Â Â Â  _onnx_model = convert_sklearn__(pipe, initial_types=initial_types__)_

Â Â Â Â Â Â Â  _with open(OUT_DIR / "temperature_risk_in_transit.onnx"__, "wb") as f:_

Â Â Â Â Â Â Â Â Â Â Â  _f.write(onnx_model.SerializeToString())

Â Â Â Â Â Â Â  print("Saved ONNX:", OUT_DIR_ _/ "temperature_risk_in_transit.onnx")

Â Â Â  except Exception as ex:

Â Â Â Â Â Â Â  print("ONNX export failed:", ex)

  

# Write predictions.csv (test set)

pred_flag_ _= (probs >= best_thr).astype(int)

out = X_test__.copy()_

_out["Temp_Excursion_True"] = y_test.values

out["Risk_Probability"__] = probs_

_out["Risk_Flag"] = pred_flag_

_out.to_csv("predictions.csv", index=False)

print("Saved predictions.csv")

  

# Optional: SHAP per-sample explanations (TreeExplainer for RF)

if SHAP_AVAILABLE__:_

Â Â Â  _# Fit explainer on the underlying RF (post-preprocessing)_

Â Â Â  _# A practical approach: fit explainer on the raw RandomForest with OHE applied_

Â Â Â  _# We get the transformed X_train/X_test from the pipeline_

Â Â Â  _X_train_tr = pipe.named_steps["prep"].fit_transform__(X_train)

Â Â Â  rf = pipe.named_steps__["model"].base_estimatorÂ  # RandomForest inside CalibratedClassifierCV

Â Â Â  explainer = shap.TreeExplainer(rf)

Â Â Â  shap_values_ _= explainer.shap_values(X_train_tr)Â  # returns list for classes; we use class 1

Â Â Â  # For test set explanations:

Â Â Â  X_test_tr = pipe.named_steps__["prep"].transform(X_test)

Â Â Â  shap_test_ _= explainer.shap_values(X_test_tr)[1]Â  # class 1 contribution

Â Â Â  # Save mean absolute SHAP per feature for test

Â Â Â  feature_names_ _= pipe.named_steps["prep"].get_feature_names_out__().tolist()_

Â Â Â  _shap_df = pd.DataFrame(shap_test__, columns=feature_names)

Â Â Â  shap_df__.to_csv("shap_values.csv"__, index=False)_

Â Â Â  _print("Saved shap_values.csv")

else:

Â Â Â  print("SHAP not installed; skipping explanations")

---

## âš™ï¸ C# serving: batch scoring + SHAP endpoint

### 1) Batch scoring endpoint â€” `/api/predict-batch`

- Accepts an **array of shipments** (JSON)
- Builds inputs with **shape [N,1]** for each ONNX feature
- Runs inference once
- Applies the **costâ€‘based threshold** (from `appsettings.json` or `threshold.txt`)
- Returns a list of `{probability, riskFlag}` (and optionally persists to DB)

> Assumes your ONNX expects the **same inâ€‘transit features** as trained.

// Program.cs (excerpt)

app.MapPost("/api/predict-batch", (ShipmentDto[] batch, InferenceSession session) =>

{

Â Â Â  if (batch == null || batch.Length == 0)

Â Â Â Â Â Â Â  return Results.BadRequest(new { error = "Empty batch" });

  

Â Â Â  float threshold = builder.Configuration.GetValue("Prediction:Threshold", 0.35f);

  

Â Â Â  int N = batch.Length;

  

Â Â Â  // Build tensors [N,1] per input

Â Â Â  // Strings

Â Â Â  var route = new DenseTensor<string>(new[] { N, 1 });

Â Â Â  var carrier = new DenseTensor<string>(new[] { N, 1 });

Â Â Â  var packaging = new DenseTensor<string>(new[] { N, 1 });

Â Â Â  var product = new DenseTensor<string>(new[] { N, 1 });

  

Â Â Â  // Numerics

Â Â Â  var shipmentSize = new DenseTensor<float>(new[] { N, 1 });

Â Â Â  var delaySofar = new DenseTensor<float>(new[] { N, 1 });

Â Â Â  var tempRolling = new DenseTensor<float>(new[] { N, 1 });

Â Â Â  var pctElapsed = new DenseTensor<float>(new[] { N, 1 });

Â Â Â  var deviationFlag = new DenseTensor<float>(new[] { N, 1 });

Â Â Â  var holidayFlag = new DenseTensor<float>(new[] { N, 1 });

Â Â Â  var monthSin = new DenseTensor<float>(new[] { N, 1 });

Â Â Â  var monthCos = new DenseTensor<float>(new[] { N, 1 });

Â Â Â  var hourSinÂ  = new DenseTensor<float>(new[] { N, 1 });

Â Â Â  var hourCosÂ  = new DenseTensor<float>(new[] { N, 1 });

  

Â Â Â  for (int i = 0; i < N; i++)

Â Â Â  {

Â Â Â Â Â Â Â  var s = batch[i];

Â Â Â Â Â Â Â  // cyclic features derived from Departure_Time (still relevant in-transit)_

Â Â Â Â Â Â Â  _float mSin = (float)Math.Sin(2 _Math.PI_ s.Departure_Time.Month / 12.0);

Â Â Â Â Â Â Â  float mCos = (float)Math.Cos(2 _Math.PI_ s.Departure_Time__.Month / 12.0);_

Â Â Â Â Â Â Â  _float hSin = (float)Math.Sin(2 _Math.PI_ s.Departure_Time.Hour / 24.0);

Â Â Â Â Â Â Â  float hCos = (float)Math.Cos(2 _Math.PI_ s.Departure_Time__.Hour / 24.0);_

Â Â Â Â Â Â Â  _route[i, 0] = s.Route_ID;

Â Â Â Â Â Â Â  carrier[i, 0] = s.Carrier;

Â Â Â Â Â Â Â  packaging[i, 0] = s.Packaging_Type__;_

Â Â Â Â Â Â Â  _product[i, 0] = s.Product_Type;

  

Â Â Â Â Â Â Â  shipmentSize[i, 0] = s.Shipment_Size__;_

Â Â Â Â Â Â Â  _delaySofar[i, 0] = s.Delay_Sofar_Hrs;_

Â Â Â Â Â Â Â  _tempRolling[i, 0] = s.External_Temp_Rolling_Avg;

Â Â Â Â Â Â Â  pctElapsed[i, 0] = s.Pct_Elapsed_Transit;

Â Â Â Â Â Â Â  deviationFlag[i, 0] = s.Deviation_Flag_ _? 1f : 0f;_

Â Â Â Â Â Â Â  _holidayFlag[i, 0] = s.Holiday_Period_Flag ? 1f : 0f;_

Â Â Â Â Â Â Â  _monthSin[i, 0] = mSin;_

Â Â Â Â Â Â Â  _monthCos[i, 0] = mCos;_

Â Â Â Â Â Â Â  _hourSin[i, 0] = hSin;_

Â Â Â Â Â Â Â  _hourCos[i, 0] = hCos;_

Â Â Â  _}_

Â Â Â  _var inputs = new List<NamedOnnxValue>

Â Â Â  {_

Â Â Â Â Â Â Â  _NamedOnnxValue.CreateFromTensor("Route_ID", route),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Carrier", carrier),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Packaging_Type"__, packaging),_

Â Â Â Â Â Â Â  _NamedOnnxValue.CreateFromTensor("Product_Type", product),

  

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Shipment_Size"__, shipmentSize),_

Â Â Â Â Â Â Â  _NamedOnnxValue.CreateFromTensor("Delay_Sofar_Hrs", delaySofar),_

Â Â Â Â Â Â Â  _NamedOnnxValue.CreateFromTensor("External_Temp_Rolling_Avg", tempRolling),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Pct_Elapsed_Transit", pctElapsed),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Deviation_Flag"__, deviationFlag),_

Â Â Â Â Â Â Â  _NamedOnnxValue.CreateFromTensor("Holiday_Period_Flag", holidayFlag),_

Â Â Â Â Â Â Â  _NamedOnnxValue.CreateFromTensor("Month_sin", monthSin),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Month_cos"__, monthCos),_

Â Â Â Â Â Â Â  _NamedOnnxValue.CreateFromTensor("Hour_sin", hourSin),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Hour_cos", hourCos),

Â Â Â  };

  

Â Â Â  using var results = session.Run(inputs);

Â Â Â  var first = results.First();

Â Â Â  var probs = first.AsEnumerable<float>().ToArray();

  

Â Â Â  var response = probs.Select(p => new {

Â Â Â Â Â Â Â  riskProbability = p,

Â Â Â Â Â Â Â  riskFlag = p >= threshold

Â Â Â  }).ToArray();

  

Â Â Â  // Optional: persist batch predictions to DB

Â Â Â  // await repository.SaveBatchPredictionsAsync(batch, response);

  

Â Â Â  return Results.Ok(response);

})

.WithName("PredictBatch")

.Produces(StatusCodes.Status200OK)

.Produces(StatusCodes.Status400BadRequest);

### 2) SHAP endpoint design â€” `/api/explain`

**Why a hybrid approach?**\ **ONNX Runtime** (C#) does not natively compute SHAP values; SHAP is computed in **Python** (TreeSHAP for tree models, KernelSHAP for generic models). You have two pragmatic options:

- **Option A (recommended): Onâ€‘theâ€‘fly SHAP via Python service**\ Expose a **FastAPI** endpoint (Python) that receives the **same features** and returns **SHAP values** + top drivers. Your C# API **proxies** the request to that service and returns the explanation.
    
- **Option B: Precompute SHAP offline and store**\ During batch jobs, compute SHAP in Python and store values in DB with `ShipmentId`. Your C# `/api/explain/{shipmentId}` just reads from DB.
    

Below I show **Option A** (proxy to Python). If you prefer Option B, Iâ€™ll adapt.

#### A) Python SHAP service (FastAPI) â€” `explain_service.py`

# explain_service.py_

_from fastapi import FastAPI_

_from pydantic import BaseModel_

_import joblib, numpy as np, shap_

_from sklearn.pipeline import Pipeline_

_  

app = FastAPI()

_

_pipe: Pipeline = joblib.load("model_artifacts/temperature_risk_in_transit.pkl")_

_  

# Fit a TreeExplainer on the underlying RandomForest (post-preprocessing)

_

_rf = pipe.named_steps["model"].base_estimator_

_prep = pipe.named_steps["prep"]

explainer = shap.TreeExplainer(rf)

  

class Shipment(BaseModel):

Â Â Â  Route_ID__: str_

Â Â Â  _Carrier: str_

Â Â Â  _Packaging_Type: str

Â Â Â  Product_Type__: str_

Â Â Â  _Shipment_Size: float

Â Â Â  Delay_Sofar_Hrs: float

Â Â Â  External_Temp_Rolling_Avg__: float_

Â Â Â  _Pct_Elapsed_Transit: float_

Â Â Â  _Deviation_Flag: bool

Â Â Â  Holiday_Period_Flag: bool

Â Â Â  Month_sin__: float_

Â Â Â  _Month_cos: float

Â Â Â  Hour_sin__: float_

Â Â Â  _Hour_cos: float

  

@app.post("/explain")

def explain(batch: list[Shipment]):

Â Â Â  # Convert to DataFrame and transform with the same preprocessor

Â Â Â  import pandas as pd

Â Â Â  df = pd.DataFrame([s.dict() for s in batch])

Â Â Â  X_tr_ _= prep.transform(df)_

Â Â Â  _shap_vals = explainer.shap_values__(X_tr)[1]Â Â  # class 1 contributions

Â Â Â  feature_names_ _= prep.get_feature_names_out().tolist()

  

Â Â Â  # Top drivers (per row): sort by absolute SHAP

Â Â Â  top = []

Â Â Â  for i in range(shap_vals__.shape[0]):_

Â Â Â Â Â Â Â  _absvals = np.abs(shap_vals[i])

Â Â Â Â Â Â Â  idx_top_ _= absvals.argsort()[::-1][:5]_

Â Â Â Â Â Â Â  _top.append([_

Â Â Â Â Â Â Â Â Â Â Â  _{"feature": feature_names[j], "value": float(shap_vals__[i, j])}_

Â Â Â Â Â Â Â Â Â Â Â  _for j in idx_top

Â Â Â Â Â Â Â  ])

  

Â Â Â  return {"featureNames": feature_names__, "shapValues": shap_vals.tolist(), "topDrivers": top}

Run:

uvicorn explain_service:app --host 0.0.0.0 --port 8001

#### B) C# proxy endpoint â€” `/api/explain`

Configure `ExplainServiceUrl` in `appsettings.json` (e.g., `http://localhost:8001/explain`), then:

// Program.cs (excerpt)

using System.Net.Http.Json;

  

app.MapPost("/api/explain", async (ShipmentDto[] batch, IConfiguration cfg) =>

{

Â Â Â  var url = cfg.GetValue<string>("Prediction:ExplainServiceUrl");

Â Â Â  if (string.IsNullOrWhiteSpace(url))

Â Â Â Â Â Â Â  return Results.BadRequest(new { error = "ExplainServiceUrl not configured." });

  

Â Â Â  using var http = new HttpClient();

Â Â Â  var resp = await http.PostAsJsonAsync(url, batch);

Â Â Â  if (!resp.IsSuccessStatusCode)

Â Â Â Â Â Â Â  return Results.StatusCode((int)resp.StatusCode);

  

Â Â Â  var payload = await resp.Content.ReadFromJsonAsync<object>();

Â Â Â  return Results.Ok(payload);

})

.WithName("ExplainBatch")

.Produces(StatusCodes.Status200OK)

.Produces(StatusCodes.Status400BadRequest);

---

## ðŸ§¾ DTO for inâ€‘transit (C#)

public sealed class ShipmentDto

{

Â Â Â  // Categorical

Â Â Â  public string Route_ID_ _{ get; set; } = "";_

Â Â Â  _public string Carrier { get; set; } = "";_

Â Â Â  _public string Packaging_Type { get; set; } = "";

Â Â Â  public string Product_Type_ _{ get; set; } = "";_

Â Â Â  _// Temporal_

Â Â Â  _public DateTime Departure_Time { get; set; }

  

Â Â Â  // In-transit numerics & flags

Â Â Â  public float Shipment_Size_ _{ get; set; }_

Â Â Â  _public float Delay_Sofar_Hrs { get; set; }_

Â Â Â  _public float External_Temp_Rolling_Avg { get; set; }

Â Â Â  public float Pct_Elapsed_Transit { get; set; }

Â Â Â  public bool Deviation_Flag_ _{ get; set; }_

Â Â Â  _public bool Holiday_Period_Flag { get; set; }

}

---

## ðŸ§ª Operational notes

- **Threshold**: Use the **costâ€‘based** threshold you saved in `threshold.txt` or `appsettings.json`. Donâ€™t lock to 0.5.
- **Versioning**: Store `modelVersion`, `threshold`, and `scoredAt` with predictions for auditability.
- **Data drift**: Monitor feature distributions (e.g., `Delay_Sofar_Hrs` spikes in holidays) and retrain monthly/quarterly.
- **Performance KPIs**: Track **PR AUC** and **Recall** on recent data; alert if they degrade.
- **SHAP in production**: Prefer **Option A** (Python service) or **Option B** (precompute & store) to keep C# serving lean.

---

## Want me to ship a readyâ€‘toâ€‘run repo?

I can package:

- `train_temperature_risk_in_transit.py` (training, cost threshold, optional ONNX + SHAP)
- ASP.NET Core **Minimal API** with:
    - `/api/predict` (single),
    - `/api/predict-batch` (batch),
    - `/api/explain` (proxy to Python SHAP),
    - health check `/health`
- `appsettings.json` wired for `OnnxPath`, `Threshold`, `ExplainServiceUrl`
- Example **Power BI** measures and a seed SQL schema for `Predictions`

Tell me if you want **EF Core** persistence included and whether you prefer **XGBoost** instead of RandomForest for better SHAP fidelity.