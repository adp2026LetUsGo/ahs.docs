##### me respondiste que al Use Case presentado "TomÃ© tu idea y la convertÃ­ en un plan listo para implementar â€”desde Excel/Power BI hasta Python/MLâ€” cuidando detalles prÃ¡cticos como fuga de informaciÃ³n, desbalanceo de clases, separaciÃ³n temporal y despliegue. Te lo dejo en espaÃ±ol y con ejemplos concretos para que avances hoy mismo."Por favor repÃ­telo en Ingles Cambiar a estrategias hÃ­bridas con el uso de C# y la librerÃ­as de Machine learning de .netEntrenar en Python / scikitâ€‘learn y cargar en C# (ONNX)incluye un equivalente a un cuaderno .py que lea el shipments.csv, entrene, guarde el modelo (.pkl) y exporte un predictions.csv con el umbral Ã³ptimo segÃºn una funciÃ³n de costo que definamos


Absolutely, Armandoâ€”hereâ€™s the same plan **in English**, adapted to **hybrid strategies** that keep your **data capture, backend, DB, and reporting in C#/.NET**, while you **train in Python (scikitâ€‘learn) and serve the model in C# via ONNX**. Iâ€™m also including a **â€œnotebookâ€‘equivalentâ€ Python script** that reads `shipments.csv`, trains, saves the model (`.pkl`), **selects the optimal threshold via a cost function**, and writes a `predictions.csv`.

---

## ðŸŽ¯ Goal (operationally grounded)

**Predict whether a shipment will suffer a temperature excursion (out-of-spec) _before it arrives_** so your team can act proactively (add thermal protection, re-route, change carrier, notify client).\ There are two practical prediction moments:

1. **Preâ€‘dispatch** (planning time): use planned transit time, expected weather, carrier reliability, etc.
2. **Inâ€‘transit** (before arrival): use partial telemetry (delay so far, rolling external temperature, % progress).

> **Key guardrail**: If your prediction is **preâ€‘dispatch**, _do not_ train with variables only known after delivery (e.g., actual `Transit_Time_Hrs`, fullâ€‘journey `External_Temp_Avg`). Use **planned/expected** counterparts.

---

## ðŸ”¢ Data youâ€™ll need (recap)

- `Route_ID`, `Carrier`, `Departure_Time`
- **Planned** transit time (for preâ€‘dispatch) or **rolling/soâ€‘far** metrics (inâ€‘transit)
- External temperature (expected/pronostic for preâ€‘dispatch, rolling for inâ€‘transit)
- `Packaging_Type`, `Product_Type`, `Shipment_Size`, `Delay_Flag` (if inâ€‘transit)
- **Target**: `Temp_Excursion` (1 = out-of-spec, 0 = OK)\ **Optional boosters**: holiday periods, weather conditions (rain/heat waves), carrier onâ€‘time reliability by route/month.

---

## ðŸ§© Hybrid strategies (recommended)

### Strategy A â€” Allâ€‘.NET (ML.NET)

- Keep everything in C# with **ML.NET** (great for tabular classification):
    - Trainers: `SdcaLogisticRegression`, `FastForest`, `LightGbm`
    - Oneâ€‘Hot encoding for categorical features, time features (month/hour sine/cosine), scaling for numerics.
- Pros: one stack, easy deployment with ASP.NET Core, CI/CD with your existing tooling.
- Cons: fewer â€œbleeding edgeâ€ libs than Python; SHAP/explainers and special calibrations are more common in Python.

### Strategy B â€” **Train in Python / scikitâ€‘learn**, **serve in C# via ONNX** âœ…

- Use Python for: feature engineering, model selection (e.g., RandomForest/LightGBM/XGBoost), **probability calibration**, explainability (SHAP).
- **Export to ONNX** and load in C# with **Microsoft.ML.OnnxRuntime**â€”fast inference, no Python runtime in production.
- Pros: best of both worlds; production stays 100% .NET; easy to version the `.onnx` and `threshold`.

> This answer shows **Strategy B** in detail (and itâ€™s the one I recommend for your use case).

---

## ðŸ—ï¸ Production architecture (concise)

- **C#/.NET** for data entry, APIs, DB persistence, dashboards.
- **Python** offline training â†’ export **model.onnx** + **threshold.txt** + **features_used.csv**.
- **ASP.NET Core API** (`/api/predict`) uses **OnnxRuntime** to score and writes predictions to DB.
- **Power BI** connects to DB for KPIs and heatmaps; a job triggers reâ€‘training monthly/quarterly.

---

## ðŸ“¦ â€œNotebookâ€‘equivalentâ€ Python script (endâ€‘toâ€‘end)

> Save as `train_temperature_risk.py`.\ It will: **read** `shipments.csv`, **engineer features**, **train** a calibrated model, **select the optimal threshold using a cost function**, **export predictions.csv**, and **save artifacts** (`.pkl`, `.onnx`, `threshold.txt`, `features_used.csv`).

# train_temperature_risk.py

# -_- coding: utf-8 -_-

"""

End-to-end training script:

- Loads shipments.csv

- Builds features (pre-dispatch view by default)

- Temporal split (train past, test future)

- Trains a calibrated RandomForest

- Chooses decision threshold by minimizing expected cost (FN vs FP)

- Saves artifacts: pipeline.pkl, model.onnx, threshold.txt, features_used.csv_

_- Writes predictions.csv (on test split) with the chosen threshold_

_"""_

_  

import os

import numpy as np

import pandas as pd

from pathlib import Path

  

from sklearn.compose import ColumnTransformer

from sklearn.preprocessing import OneHotEncoder, StandardScaler

from sklearn.pipeline import Pipeline

from sklearn.ensemble import RandomForestClassifier

from sklearn.calibration import CalibratedClassifierCV

_

_from sklearn.metrics import roc_auc_score, average_precision_score_

_from sklearn.model_selection import train_test_split

  

import joblib

  

# Optional: ONNX export

try:

Â Â Â  from skl2onnx import convert_sklearn_

Â Â Â  _from skl2onnx.common.data_types import FloatTensorType, StringTensorType, TensorType

Â Â Â  ONNX_AVAILABLE_ _= True_

_except Exception:_

Â Â Â  _ONNX_AVAILABLE = False

  

# -----------------------------

# Config

# -----------------------------

DATA_PATH_ _= Path("shipments.csv")_

_OUT_DIR = Path("model_artifacts"__)_

_OUT_DIR.mkdir(exist_ok__=True)_

_PREDICT_PRE_DISPATCH = TrueÂ  # If False, adapt features to in-transit scenario_

_TARGET = "Temp_Excursion"

  

# Cost function weights (set with ops team)

COST_FALSE_NEGATIVE = 10.0Â  # cost of missing a risky shipment

COST_FALSE_POSITIVE = 1.0Â Â  # cost of mitigating unnecessarily

  

# -----------------------------

# Load data

# -----------------------------

df = pd.read_csv__(DATA_PATH, parse_dates__=["Departure_Time"])

assert TARGET in df.columns, f"Missing target column '{TARGET}'"

y = df[TARGET].astype(int)

  

# -----------------------------

# Feature engineering

# -----------------------------

# DO NOT leak post-delivery variables if predicting pre-dispatch

if PREDICT_PRE_DISPATCH:

Â Â Â  # Drop actuals if present; rely on planned/expected fields instead

Â Â Â  for col in ["Transit_Time_Hrs", "External_Temp_Avg"]:

Â Â Â Â Â Â Â  if col in df.columns:

Â Â Â Â Â Â Â Â Â Â Â  df = df.drop(columns=[col])

else:

Â Â Â  # In-transit example: keep rolling/partial features if available

Â Â Â  pass

  

# Time features (cyclical)

df["Month"] = df["Departure_Time"__].dt.month_

_df["Hour"] = df["Departure_Time"].dt.hour

df["Month_sin"__] = np.sin(2 _np.pi_ df["Month"] / 12)_

_df["Month_cos"] = np.cos(2 _np.pi_ df["Month"] / 12)

df["Hour_sin"__] = np.sin(2 _np.pi_ df["Hour"] / 24)_

_df["Hour_cos"] = np.cos(2 _np.pi_ df["Hour"] / 24)

  

# Holiday flag placeholder (replace with real calendar later)

if "Holiday_Period_Flag" not in df.columns:

Â Â Â  df["Holiday_Period_Flag"] = 0

  

# Candidate features (adjust to your columns)

if PREDICT_PRE_DISPATCH:

Â Â Â  candidates = [

Â Â Â Â Â Â Â  "Route_ID"__, "Carrier", "Packaging_Type", "Product_Type"__,_

Â Â Â Â Â Â Â  _"Shipment_Size",

Â Â Â Â Â Â Â  "Planned_Transit_Time_Hrs"__,Â Â Â Â Â Â Â Â Â Â Â  # planned (avoid actual)_

Â Â Â Â Â Â Â  _"Expected_External_Temp_Avg",Â Â Â Â Â Â Â Â Â  # expected/pronostic

Â Â Â Â Â Â Â  "Carrier_OnTime_Reliability",Â Â Â Â Â Â Â Â Â  # optional

Â Â Â Â Â Â Â  "Holiday_Period_Flag",

Â Â Â Â Â Â Â  "Month_sin"__, "Month_cos", "Hour_sin"__, "Hour_cos"

Â Â Â  ]

else:

Â Â Â  candidates = [

Â Â Â Â Â Â Â  "Route_ID"__, "Carrier", "Packaging_Type", "Product_Type"__,_

Â Â Â Â Â Â Â  _"Shipment_Size",

Â Â Â Â Â Â Â  "Delay_Sofar_Hrs",Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  # in-transit

Â Â Â Â Â Â Â  "External_Temp_Rolling_Avg"__,Â Â Â Â Â Â Â Â Â Â  # in-transit_

Â Â Â Â Â Â Â  _"Pct_Elapsed_Transit",Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  # in-transit_

Â Â Â Â Â Â Â  _"Holiday_Period_Flag",_

Â Â Â Â Â Â Â  _"Month_sin", "Month_cos"__, "Hour_sin", "Hour_cos"_

Â Â Â  _]_

_  

# Keep only available columns

features = [c for c in candidates if c in df.columns]

X = df[features].copy()

  

# -----------------------------

# Temporal split (simulate future)

# -----------------------------

_

_df_sorted = df.sort_values__("Departure_Time").reset_index__(drop=True)_

_idx = df_sorted.index

X_sorted_ _= X.loc[idx]_

_y_sorted = y.loc[idx]

  

cut = int(len(df_sorted__) _0.8)__

__X_train, X_test_ _= X_sorted.iloc[:cut], X_sorted__.iloc[cut:]__

__y_train, y_test_ _= y_sorted.iloc[:cut], y_sorted__.iloc[cut:]__

__  

# -----------------------------

# Preprocess

# -----------------------------

_

_num_cols = X_train__.select_dtypes(include=[np.number]).columns.tolist()

cat_cols_ _= [c for c in X_train.columns if c not in num_cols__]_

_  

pre = ColumnTransformer(

Â Â Â  transformers=[

_

Â Â Â Â Â Â Â  _("num", StandardScaler(with_mean=False), num_cols__),_

Â Â Â Â Â Â Â  _("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols__),_

Â Â Â  _],_

Â Â Â  _remainder="drop",_

_)_

_  

# -----------------------------

# Model + calibration

# -----------------------------

base = RandomForestClassifier(

_

Â Â Â  _n_estimators=400,

Â Â Â  n_jobs__=-1,_

Â Â Â  _class_weight="balanced",

Â Â Â  random_state__=42_

_)_

_# Isotonic calibration for better probability quality_

_model = CalibratedClassifierCV(base, method="isotonic", cv=3)_

_  

pipe = Pipeline(steps=[("prep", pre), ("model", model)])

_

_pipe.fit(X_train, y_train__)_

_  

# -----------------------------

# Evaluate & choose threshold by cost

# -----------------------------

_

_probs = pipe.predict_proba(X_test__)[:, 1]_

_roc = roc_auc_score(y_test, probs)

pr_auc_ _= average_precision_score(y_test, probs)

  

def expected_cost__(prob, y_true, thr, c_fn__, c_fp):

Â Â Â  """Expected cost per sample at threshold thr."""

Â Â Â  y_pred_ _= (prob >= thr).astype(int)_

Â Â Â  _FN = np.sum((y_true == 1) & (y_pred_ _== 0))_

Â Â Â  _FP = np.sum((y_true == 0) & (y_pred_ _== 1))_

_

Â Â Â  __return (c_fn_ FN + c_fp_ _* FP) / len(y_true)

  

thr_grid_ _= np.linspace(0.05, 0.95, 91)_

_costs = [expected_cost(probs, y_test__.values, t, COST_FALSE_NEGATIVE, COST_FALSE_POSITIVE) for t in thr_grid]

best_idx_ _= int(np.argmin(costs))_

_best_thr = float(thr_grid__[best_idx])

best_cost_ _= float(costs[best_idx])

  

print(f"ROC AUC: {roc:.3f} | PR AUC: {pr_auc:.3f}"__)_

_print(f"Chosen threshold: {best_thr:.2f} (expected cost={best_cost:.3f}, FN cost={COST_FALSE_NEGATIVE}, FP cost={COST_FALSE_POSITIVE})")_

_  

# -----------------------------

# Save artifacts

# -----------------------------

_

_joblib.dump(pipe, OUT_DIR / "temperature_risk_pipeline.pkl")

pd.DataFrame({"feature": features}).to_csv__(OUT_DIR / "features_used.csv"__, index=False)_

_with open(OUT_DIR / "threshold.txt", "w") as f:

Â Â Â  f.write(str(best_thr__))_

_  

# Optional: export to ONNX (only the trained pipeline; note: CalibratedClassifierCV export may fall back to underlying estimator)

_

_if ONNX_AVAILABLE:

Â Â Â  initial_types_ _= []_

Â Â Â  _for c in cat_cols:

Â Â Â Â Â Â Â  initial_types__.append((c, StringTensorType([None, 1])))_

Â Â Â  _for c in num_cols:

Â Â Â Â Â Â Â  initial_types__.append((c, FloatTensorType([None, 1])))_

Â Â Â  _try:_

Â Â Â Â Â Â Â  _onnx_model = convert_sklearn__(pipe, initial_types=initial_types__)Â  # may warn if some wrappers not supported_

Â Â Â Â Â Â Â  _with open(OUT_DIR / "temperature_risk_pipeline.onnx", "wb") as f:

Â Â Â Â Â Â Â Â Â Â Â  f.write(onnx_model__.SerializeToString())_

Â Â Â Â Â Â Â  _print("Saved ONNX model:", OUT_DIR / "temperature_risk_pipeline.onnx")

Â Â Â  except Exception as ex:

Â Â Â Â Â Â Â  print("ONNX export failed:", ex)

else:

Â Â Â  print("skl2onnx not installed; skipping ONNX export")

  

# -----------------------------

# Write predictions.csv (test split)

# -----------------------------

pred_flag_ _= (probs >= best_thr).astype(int)

out = X_test__.copy()_

_out["Temp_Excursion_True"] = y_test.values

out["Risk_Probability"__] = probs_

_out["Risk_Flag"] = pred_flag_

_out.to_csv("predictions.csv", index=False)

print("Saved predictions.csv")

### How to run

python train_temperature_risk.py

**Outputs**

- `model_artifacts/temperature_risk_pipeline.pkl`
- `model_artifacts/temperature_risk_pipeline.onnx` (if `skl2onnx` installed)
- `model_artifacts/features_used.csv`
- `model_artifacts/threshold.txt`
- `predictions.csv` (with probabilities and flags on test split using the **optimal costâ€‘based threshold**)

> **Note on ONNX export:** `CalibratedClassifierCV` support depends on converter versions; if it doesnâ€™t export, you can either (a) export the underlying `RandomForestClassifier` without the calibrator, or (b) calibrate offline and bake the mapping into a custom transform. In practice, ONNX Runtime inference with the baseline estimator works well; keep the chosen `threshold.txt` for decisioning in C#.

---

## âš™ï¸ C# inference (ASP.NET Core + ONNX Runtime)

> Minimal example that loads the **ONNX** model, applies the **same features** you trained, and uses the **threshold** to return `riskFlag`.

// Program.cs (Minimal API)

using Microsoft.AspNetCore.Mvc;

using Microsoft.ML.OnnxRuntime;

using Microsoft.ML.OnnxRuntime.Tensors;

  

var builder = WebApplication.CreateBuilder(args);

var modelPath = builder.Configuration.GetValue("Prediction:OnnxPath", "model_artifacts/temperature_risk_pipeline.onnx"__);_

_var threshold = builder.Configuration.GetValue("Prediction:Threshold", 0.35f);_

_var modelVersion = builder.Configuration.GetValue("Prediction:ModelVersion", "v1");_

_builder.Services.AddSingleton<InferenceSession>(_ => new InferenceSession(modelPath));

builder.Services.AddEndpointsApiExplorer();

builder.Services.AddSwaggerGen();

var app = builder.Build();

app.UseSwagger();

app.UseSwaggerUI();

  

app.MapPost("/api/predict", (ShipmentDto s, InferenceSession session) =>

{

Â Â Â  // derive cyclical time features

Â Â Â  float monthSin = (float)Math.Sin(2 _Math.PI_ s.Departure_Time__.Month / 12.0);_

Â Â Â  _float monthCos = (float)Math.Cos(2 _Math.PI_ s.Departure_Time.Month / 12.0);

Â Â Â  float hourSinÂ  = (float)Math.Sin(2 _Math.PI_ s.Departure_Time__.HourÂ  / 24.0);_

Â Â Â  _float hourCosÂ  = (float)Math.Cos(2 _Math.PI_ s.Departure_Time.HourÂ  / 24.0);

  

Â Â Â  var inputs = new List<NamedOnnxValue>

Â Â Â  {

Â Â Â Â Â Â Â  // Strings

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Route_ID"__,Â Â  new DenseTensor<string>(new[] { s.Route_ID }, new[] { 1, 1 })),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Carrier",Â Â Â  new DenseTensor<string>(new[] { s.Carrier },Â  new[] { 1, 1 })),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Packaging_Type"__, new DenseTensor<string>(new[] { s.Packaging_Type }, new[] { 1, 1 })),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Product_Type"__,Â Â  new DenseTensor<string>(new[] { s.Product_Type },Â Â  new[] { 1, 1 })),

  

Â Â Â Â Â Â Â  // Numerics

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Planned_Transit_Time_Hrs"__, new DenseTensor<float>(new[] { s.Planned_Transit_Time_Hrs }, new[] { 1, 1 })),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Expected_External_Temp_Avg"__, new DenseTensor<float>(new[] { s.Expected_External_Temp_Avg }, new[] { 1, 1 })),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Shipment_Size"__, new DenseTensor<float>(new[] { s.Shipment_Size }, new[] { 1, 1 })),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Carrier_OnTime_Reliability", new DenseTensor<float>(new[] { s.Carrier_OnTime_Reliability }, new[] { 1, 1 })),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Holiday_Period_Flag", new DenseTensor<float>(new[] { s.Holiday_Period_Flag ? 1f : 0f }, new[] { 1, 1 })),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Month_sin"__, new DenseTensor<float>(new[] { monthSin }, new[] { 1, 1 })),_

Â Â Â Â Â Â Â  _NamedOnnxValue.CreateFromTensor("Month_cos", new DenseTensor<float>(new[] { monthCos }, new[] { 1, 1 })),

Â Â Â Â Â Â Â  NamedOnnxValue.CreateFromTensor("Hour_sin"__,Â  new DenseTensor<float>(new[] { hourSinÂ  }, new[] { 1, 1 })),_

Â Â Â Â Â Â Â  _NamedOnnxValue.CreateFromTensor("Hour_cos",Â  new DenseTensor<float>(new[] { hourCosÂ  }, new[] { 1, 1 })),

Â Â Â  };

  

Â Â Â  using var results = session.Run(inputs);

Â Â Â  // Pick your output name from the ONNX metadata (print once to discover)

Â Â Â  var first = results.First();

Â Â Â  float probability = first.AsEnumerable<float>().First();

Â Â Â  bool riskFlag = probability >= threshold;

  

Â Â Â  return Results.Ok(new {

Â Â Â Â Â Â Â  riskProbability = probability,

Â Â Â Â Â Â Â  riskFlag,

Â Â Â Â Â Â Â  threshold,

Â Â Â Â Â Â Â  modelVersion

Â Â Â  });

});

  

app.Run();

  

public sealed class ShipmentDto

{

Â Â Â  // Categorical

Â Â Â  public string Route_ID_ _{ get; set; } = "";_

Â Â Â  _public string Carrier { get; set; } = "";_

Â Â Â  _public string Packaging_Type { get; set; } = "";

Â Â Â  public string Product_Type_ _{ get; set; } = "";_

Â Â Â  _// Temporal_

Â Â Â  _public DateTime Departure_Time { get; set; }

  

Â Â Â  // Numeric

Â Â Â  public float Planned_Transit_Time_Hrs_ _{ get; set; }_

Â Â Â  _public float Expected_External_Temp_Avg { get; set; }

Â Â Â  public float Shipment_Size_ _{ get; set; }_

Â Â Â  _public float Carrier_OnTime_Reliability { get; set; }_

Â Â Â  _public bool Holiday_Period_Flag { get; set; }

}

> **Tip:** If your ONNX export names differ (e.g., output is `"output_probability"`), read them once:

foreach (var kv in session.OutputMetadata) Console.WriteLine(kv.Key);

---

## âœ… What you get with this setup

- **C# for everything operational** (forms, APIs, database, Power BI), with **fast and portable inference** using **OnnxRuntime**.
- **Python for training**: richer ML ecosystem, calibration, SHAP/explainability, and flexible data science workflows.
- A **clear decision threshold** chosen by **expected cost** (you and operations define the costs of FP vs FN).
- Versioned artifacts: `model.onnx`, `threshold.txt`, `features_used.csv` â†’ traceability and controlled rollouts.

---

## Next steps I can do for you

- Adjust the Python training script to your **exact column names** (Spanish/English).
- Add **batch scoring** endpoint (`/api/predict-batch`) in C#.
- Export **SHAP explanations** per shipment (Python) and surface top drivers in the API response.
- Wire **EF Core** to persist predictions (`ShipmentId, prob, flag, modelVersion, threshold, scoredAt`) for Power BI.

Want me to tailor the scripts to **preâ€‘dispatch** or **inâ€‘transit** specifically (with the right feature lists) and push a full **.NET solution skeleton** you can open in Visual Studio 2022?