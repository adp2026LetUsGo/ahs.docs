---
title: Attention Mechanisms
created: 2026-02-05
updated: 2026-02-05
tags: [llm, architecture]
---

# Attention Mechanisms

Scaled dot-product attention, multi-head attention.
